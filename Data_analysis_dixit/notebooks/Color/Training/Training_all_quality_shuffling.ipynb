{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from feature_engine.selection import DropCorrelatedFeatures\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance, SelectByShuffling, RecursiveFeatureElimination, RecursiveFeatureAddition, DropConstantFeatures\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, accuracy_score, classification_report, f1_score\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import glob\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feature_engine in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from feature_engine) (1.21.5)\n",
      "Requirement already satisfied: statsmodels>=0.11.1 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from feature_engine) (0.13.2)\n",
      "Requirement already satisfied: pandas>=1.0.3 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from feature_engine) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from feature_engine) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from feature_engine) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.3->feature_engine) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from pandas>=1.0.3->feature_engine) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.3->feature_engine) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->feature_engine) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->feature_engine) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.11.1->feature_engine) (0.5.2)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.11.1->feature_engine) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.11.1->feature_engine) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install feature_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from imblearn) (0.9.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.1.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from imbalanced-learn->imblearn) (1.21.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: scipy in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.7.3)\n",
      "Requirement already satisfied: numpy in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.21.5)\n",
      "Requirement already satisfied: wheel in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from lightgbm) (0.37.1)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from lightgbm) (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from scikit-learn!=0.22.0->lightgbm) (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (3.0.9)\n",
      "Requirement already satisfied: et-xmlfile in /home/pankaj_v/anaconda3/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv (180, 1060)\n",
      "csv (244, 1060)\n",
      "csv (24, 1060)\n",
      "csv (200, 1060)\n",
      "csv (302, 1060)\n",
      "csv (16, 1060)\n",
      "csv (72, 1060)\n",
      "csv (244, 1060)\n",
      "csv (48, 1060)\n",
      "csv (90, 1060)\n",
      "csv (314, 1060)\n",
      "csv (78, 1060)\n",
      "csv (191, 1060)\n",
      "csv (310, 1060)\n",
      "csv (294, 1060)\n",
      "csv (132, 1059)\n",
      "csv (224, 1060)\n",
      "csv (224, 1060)\n",
      "csv (18, 1060)\n",
      "csv (236, 1060)\n",
      "csv (160, 1060)\n",
      "csv (42, 1060)\n",
      "csv (246, 1060)\n",
      "csv (302, 1060)\n",
      "csv (262, 1060)\n",
      "csv (162, 1060)\n",
      "csv (142, 1060)\n",
      "csv (154, 1060)\n",
      "csv (256, 1060)\n",
      "csv (192, 1060)\n",
      "csv (252, 1060)\n",
      "csv (78, 1060)\n",
      "csv (270, 1060)\n",
      "csv (186, 1060)\n",
      "csv (29, 1060)\n",
      "csv (276, 1060)\n",
      "csv (120, 1060)\n",
      "csv (80, 1060)\n",
      "csv (28, 1060)\n",
      "csv (249, 1060)\n",
      "csv (120, 1060)\n",
      "csv (248, 1060)\n",
      "csv (348, 1060)\n",
      "csv (290, 1060)\n",
      "csv (102, 1060)\n",
      "csv (180, 1060)\n",
      "csv (110, 1060)\n",
      "csv (198, 1060)\n",
      "csv (132, 1060)\n",
      "csv (222, 1060)\n",
      "csv (77, 1060)\n",
      "csv (110, 1060)\n",
      "csv (10, 1060)\n",
      "csv (60, 1060)\n",
      "csv (254, 1060)\n",
      "csv (36, 1060)\n",
      "xlx (680, 1059)\n",
      "csv (210, 1060)\n",
      "csv (326, 1060)\n",
      "csv (90, 1060)\n",
      "csv (180, 1060)\n",
      "csv (230, 1060)\n",
      "csv (250, 1060)\n",
      "csv (302, 1060)\n",
      "csv (358, 1060)\n",
      "csv (246, 1060)\n",
      "csv (274, 1060)\n",
      "csv (96, 1060)\n",
      "xlx (224, 1059)\n",
      "csv (238, 1060)\n",
      "csv (240, 1060)\n",
      "csv (92, 1060)\n",
      "csv (248, 1060)\n",
      "csv (80, 1060)\n",
      "csv (184, 1060)\n",
      "csv (240, 1060)\n",
      "csv (374, 1060)\n",
      "csv (254, 1060)\n",
      "csv (322, 1060)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "frames = []\n",
    "for name in os.listdir('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/client_data'):\n",
    "    extents = os.path.splitext('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/client_data'+'/{}'.format(name))[1].lower()\n",
    "    if extents == '.csv':\n",
    "        df= pd.read_csv('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/client_data/{}'.format(name))\n",
    "        frames.append(df)\n",
    "        print('csv',df.shape)\n",
    "    elif extents == '.xlsx':\n",
    "        df= pd.read_excel('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/client_data/{}'.format(name))\n",
    "        df.columns = df.columns.astype(str)\n",
    "        frames.append(df)\n",
    "        print('xlx',df.shape)\n",
    "\n",
    "result =  pd.concat(frames, axis=0, ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>L*</th>\n",
       "      <th>a*</th>\n",
       "      <th>b*</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Dominant Wavelenght</th>\n",
       "      <th>Whiteness</th>\n",
       "      <th>Purity</th>\n",
       "      <th>...</th>\n",
       "      <th>979.335</th>\n",
       "      <th>980.054</th>\n",
       "      <th>980.772</th>\n",
       "      <th>981.491</th>\n",
       "      <th>982.209</th>\n",
       "      <th>982.928</th>\n",
       "      <th>983.646</th>\n",
       "      <th>984.364</th>\n",
       "      <th>985.082</th>\n",
       "      <th>Unnamed: 1059</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W_Calibration</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>95.0422</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>108.8760</td>\n",
       "      <td>565.016</td>\n",
       "      <td>99.9909</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F_Calibration</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>108.1040</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>39.2965</td>\n",
       "      <td>491.070</td>\n",
       "      <td>99.9909</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W_Calibration</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>95.0422</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>108.8760</td>\n",
       "      <td>565.016</td>\n",
       "      <td>99.9909</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F_Calibration</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>108.1040</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>39.2965</td>\n",
       "      <td>491.070</td>\n",
       "      <td>99.9909</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>...</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W_3566A2/33_H_Faint_0.30_SI1</td>\n",
       "      <td>99.7016</td>\n",
       "      <td>-0.840692</td>\n",
       "      <td>1.97141</td>\n",
       "      <td>93.8345</td>\n",
       "      <td>99.2302</td>\n",
       "      <td>104.8660</td>\n",
       "      <td>569.412</td>\n",
       "      <td>90.5883</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>...</td>\n",
       "      <td>97.4079</td>\n",
       "      <td>97.6368</td>\n",
       "      <td>98.0312</td>\n",
       "      <td>97.8384</td>\n",
       "      <td>97.8231</td>\n",
       "      <td>-33.8442</td>\n",
       "      <td>-71.7545</td>\n",
       "      <td>-33.0428</td>\n",
       "      <td>-1563.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1060 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       L*        a*       b*         X  \\\n",
       "0                 W_Calibration  100.0000  0.000000  0.00000   95.0422   \n",
       "1                 F_Calibration  100.0000  0.000000  0.00000  108.1040   \n",
       "2                 W_Calibration  100.0000  0.000000  0.00000   95.0422   \n",
       "3                 F_Calibration  100.0000  0.000000  0.00000  108.1040   \n",
       "4  W_3566A2/33_H_Faint_0.30_SI1   99.7016 -0.840692  1.97141   93.8345   \n",
       "\n",
       "          Y         Z  Dominant Wavelenght  Whiteness    Purity  ...  \\\n",
       "0  100.0000  108.8760              565.016    99.9909  0.000017  ...   \n",
       "1  100.0000   39.2965              491.070    99.9909  0.000170  ...   \n",
       "2  100.0000  108.8760              565.016    99.9909  0.000017  ...   \n",
       "3  100.0000   39.2965              491.070    99.9909  0.000170  ...   \n",
       "4   99.2302  104.8660              569.412    90.5883  0.017551  ...   \n",
       "\n",
       "    979.335   980.054   980.772   981.491   982.209   982.928   983.646  \\\n",
       "0  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000   \n",
       "1  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000   \n",
       "2  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000   \n",
       "3  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000  100.0000   \n",
       "4   97.4079   97.6368   98.0312   97.8384   97.8231  -33.8442  -71.7545   \n",
       "\n",
       "    984.364  985.082  Unnamed: 1059  \n",
       "0  100.0000   100.00            NaN  \n",
       "1  100.0000   100.00            NaN  \n",
       "2  100.0000   100.00            NaN  \n",
       "3  100.0000   100.00            NaN  \n",
       "4  -33.0428 -1563.49            NaN  \n",
       "\n",
       "[5 rows x 1060 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data PrePrpcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns = {' ': 'Output'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_3 =result.loc[:,'Output']\n",
    "result_2= result.loc[:,'300.377':'700.577']\n",
    "result_1= result.iloc[:,1:14]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([result_2, result_3], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15162, 524)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/Processed_data/whole_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_calb = df[~df['Output'].str.contains(('Calibration|CALIBARTION|CALIBARATION'),case=False, regex=True, na = False)]\n",
    "df_without_calb.reset_index(drop=True)\n",
    "df_without_calb['w/f']= df_without_calb['Output'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_w = df_without_calb[df_without_calb['w/f'] == 'W']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2032800'"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_w.size.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_w['quality'] = df_with_w['Output'].str.split('_').str[3]\n",
    "df_with_w['quality'].replace({'lb':'Faint','Benth':'None','brown':'None','Pink':'None', 'LB':'None','LB ':'None', 'Faint YELLOW':'Faint', 'Faint YELLOW':'Faint', 'Faint GREEN':'Faint','  ':'None', 'BROWN':'Faint', 'Lblack':'Faint', 'lb ':'None','Black':'None'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_w['color'] = df_with_w['Output'].str.split('_').str[2]\n",
    "df_with_w['color'].replace({'d':'D','H/BLK':'H','E/LB':'E','H/LB':'H','J/LB':'J','I/LB':'I','J ':'J','F/LB':'F','G/LB':'G','E LB':'E', ' K':'K', 'G LB ':'G', 'H ':'H'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_w.drop((df_with_w[df_with_w.color.str.contains('\\s', regex=True)].index|df_with_w[df_with_w['color'] == ''].index|df_with_w[df_with_w['quality'].str.contains('\\s\\W', regex=True)].index|df_with_w[df_with_w['color'].str.contains('\\s\\W', regex=True)].index|df_with_w[df_with_w['quality'].str.contains(('^\\s'), regex=True)].index), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_w.drop(columns=['Output','w/f'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_w = df_with_w[~(df_with_w['quality'] == 'Strong')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_w.to_csv('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/Processed_data/df_w_1_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "None           2818\n",
       "Faint          1148\n",
       "Very Strong     656\n",
       "Medium          377\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_w.quality.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visu = df_with_w.copy()\n",
    "df_visu.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65.1567"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visu['300.377'].astype('float').min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reomoving Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_visu.drop(index = df_visu['300.377'].ast/ype('float').idxmax(), inplace=True)\n",
    "# df_visu.drop(index=df_visu['300.377'].astype('float').idxmin(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>300.377</th>\n",
       "      <th>301.162</th>\n",
       "      <th>301.946</th>\n",
       "      <th>302.731</th>\n",
       "      <th>303.515</th>\n",
       "      <th>304.299</th>\n",
       "      <th>305.083</th>\n",
       "      <th>305.867</th>\n",
       "      <th>306.652</th>\n",
       "      <th>307.435</th>\n",
       "      <th>...</th>\n",
       "      <th>695.339</th>\n",
       "      <th>696.087</th>\n",
       "      <th>696.836</th>\n",
       "      <th>697.584</th>\n",
       "      <th>698.332</th>\n",
       "      <th>699.081</th>\n",
       "      <th>699.829</th>\n",
       "      <th>700.577</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93.9613</td>\n",
       "      <td>93.5905</td>\n",
       "      <td>93.5144</td>\n",
       "      <td>93.5858</td>\n",
       "      <td>94.0028</td>\n",
       "      <td>93.9788</td>\n",
       "      <td>94.2287</td>\n",
       "      <td>93.9844</td>\n",
       "      <td>94.2687</td>\n",
       "      <td>94.7686</td>\n",
       "      <td>...</td>\n",
       "      <td>99.3325</td>\n",
       "      <td>99.3291</td>\n",
       "      <td>99.3268</td>\n",
       "      <td>99.3363</td>\n",
       "      <td>99.3128</td>\n",
       "      <td>99.3191</td>\n",
       "      <td>99.3499</td>\n",
       "      <td>99.3758</td>\n",
       "      <td>Faint</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95.5023</td>\n",
       "      <td>95.4314</td>\n",
       "      <td>95.2679</td>\n",
       "      <td>95.4398</td>\n",
       "      <td>96.0739</td>\n",
       "      <td>96.0221</td>\n",
       "      <td>96.2585</td>\n",
       "      <td>96.0292</td>\n",
       "      <td>96.0922</td>\n",
       "      <td>96.1002</td>\n",
       "      <td>...</td>\n",
       "      <td>100.3670</td>\n",
       "      <td>100.3130</td>\n",
       "      <td>100.2990</td>\n",
       "      <td>100.2630</td>\n",
       "      <td>100.2110</td>\n",
       "      <td>100.1920</td>\n",
       "      <td>100.1960</td>\n",
       "      <td>100.2210</td>\n",
       "      <td>None</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96.7677</td>\n",
       "      <td>96.5512</td>\n",
       "      <td>96.1780</td>\n",
       "      <td>96.4226</td>\n",
       "      <td>96.8096</td>\n",
       "      <td>96.9811</td>\n",
       "      <td>96.8336</td>\n",
       "      <td>96.8316</td>\n",
       "      <td>97.0489</td>\n",
       "      <td>96.5584</td>\n",
       "      <td>...</td>\n",
       "      <td>100.5560</td>\n",
       "      <td>100.5590</td>\n",
       "      <td>100.5620</td>\n",
       "      <td>100.5480</td>\n",
       "      <td>100.5370</td>\n",
       "      <td>100.5330</td>\n",
       "      <td>100.5110</td>\n",
       "      <td>100.4660</td>\n",
       "      <td>None</td>\n",
       "      <td>H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92.1969</td>\n",
       "      <td>91.9748</td>\n",
       "      <td>91.8531</td>\n",
       "      <td>92.1156</td>\n",
       "      <td>92.3446</td>\n",
       "      <td>92.4588</td>\n",
       "      <td>92.2696</td>\n",
       "      <td>92.1126</td>\n",
       "      <td>92.2204</td>\n",
       "      <td>91.8990</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0999</td>\n",
       "      <td>99.1498</td>\n",
       "      <td>99.1580</td>\n",
       "      <td>99.1579</td>\n",
       "      <td>99.2034</td>\n",
       "      <td>99.2142</td>\n",
       "      <td>99.2092</td>\n",
       "      <td>99.1851</td>\n",
       "      <td>None</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.9493</td>\n",
       "      <td>97.5832</td>\n",
       "      <td>97.8770</td>\n",
       "      <td>97.8452</td>\n",
       "      <td>98.2188</td>\n",
       "      <td>98.1894</td>\n",
       "      <td>98.1268</td>\n",
       "      <td>98.2943</td>\n",
       "      <td>97.7774</td>\n",
       "      <td>97.8066</td>\n",
       "      <td>...</td>\n",
       "      <td>101.1530</td>\n",
       "      <td>101.1980</td>\n",
       "      <td>101.2170</td>\n",
       "      <td>101.2350</td>\n",
       "      <td>101.2070</td>\n",
       "      <td>101.2170</td>\n",
       "      <td>101.2320</td>\n",
       "      <td>101.2150</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>102.0850</td>\n",
       "      <td>102.2880</td>\n",
       "      <td>102.4110</td>\n",
       "      <td>102.7420</td>\n",
       "      <td>102.2430</td>\n",
       "      <td>102.2220</td>\n",
       "      <td>102.2150</td>\n",
       "      <td>102.2560</td>\n",
       "      <td>102.2080</td>\n",
       "      <td>102.2340</td>\n",
       "      <td>...</td>\n",
       "      <td>103.4040</td>\n",
       "      <td>103.4020</td>\n",
       "      <td>103.4040</td>\n",
       "      <td>103.4300</td>\n",
       "      <td>103.4020</td>\n",
       "      <td>103.4220</td>\n",
       "      <td>103.4880</td>\n",
       "      <td>103.4690</td>\n",
       "      <td>None</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>97.9494</td>\n",
       "      <td>98.1799</td>\n",
       "      <td>98.3628</td>\n",
       "      <td>98.0291</td>\n",
       "      <td>98.3103</td>\n",
       "      <td>98.4854</td>\n",
       "      <td>98.0282</td>\n",
       "      <td>97.5581</td>\n",
       "      <td>97.6816</td>\n",
       "      <td>97.6634</td>\n",
       "      <td>...</td>\n",
       "      <td>99.8242</td>\n",
       "      <td>99.8488</td>\n",
       "      <td>99.8604</td>\n",
       "      <td>99.8668</td>\n",
       "      <td>99.8569</td>\n",
       "      <td>99.8530</td>\n",
       "      <td>99.8555</td>\n",
       "      <td>99.8538</td>\n",
       "      <td>Faint</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>96.4612</td>\n",
       "      <td>96.7232</td>\n",
       "      <td>96.9706</td>\n",
       "      <td>96.8789</td>\n",
       "      <td>96.7985</td>\n",
       "      <td>97.1090</td>\n",
       "      <td>97.2549</td>\n",
       "      <td>97.4836</td>\n",
       "      <td>97.5302</td>\n",
       "      <td>97.3204</td>\n",
       "      <td>...</td>\n",
       "      <td>99.9035</td>\n",
       "      <td>99.9315</td>\n",
       "      <td>99.9107</td>\n",
       "      <td>99.9335</td>\n",
       "      <td>99.9170</td>\n",
       "      <td>99.9572</td>\n",
       "      <td>99.9600</td>\n",
       "      <td>99.9568</td>\n",
       "      <td>None</td>\n",
       "      <td>G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>97.1866</td>\n",
       "      <td>97.0617</td>\n",
       "      <td>97.2634</td>\n",
       "      <td>97.6980</td>\n",
       "      <td>97.2498</td>\n",
       "      <td>97.3879</td>\n",
       "      <td>97.5460</td>\n",
       "      <td>97.7210</td>\n",
       "      <td>98.4481</td>\n",
       "      <td>98.3731</td>\n",
       "      <td>...</td>\n",
       "      <td>100.8130</td>\n",
       "      <td>100.8300</td>\n",
       "      <td>100.8580</td>\n",
       "      <td>100.8570</td>\n",
       "      <td>100.8590</td>\n",
       "      <td>100.8910</td>\n",
       "      <td>100.9130</td>\n",
       "      <td>100.9130</td>\n",
       "      <td>None</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>101.1130</td>\n",
       "      <td>101.0970</td>\n",
       "      <td>100.8730</td>\n",
       "      <td>101.0810</td>\n",
       "      <td>101.0900</td>\n",
       "      <td>101.1650</td>\n",
       "      <td>101.3450</td>\n",
       "      <td>101.2900</td>\n",
       "      <td>101.3780</td>\n",
       "      <td>101.2470</td>\n",
       "      <td>...</td>\n",
       "      <td>101.5080</td>\n",
       "      <td>101.5290</td>\n",
       "      <td>101.5220</td>\n",
       "      <td>101.4920</td>\n",
       "      <td>101.5190</td>\n",
       "      <td>101.5670</td>\n",
       "      <td>101.5660</td>\n",
       "      <td>101.5690</td>\n",
       "      <td>None</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4993 rows × 525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       300.377   301.162   301.946   302.731   303.515   304.299   305.083  \\\n",
       "0      93.9613   93.5905   93.5144   93.5858   94.0028   93.9788   94.2287   \n",
       "1      95.5023   95.4314   95.2679   95.4398   96.0739   96.0221   96.2585   \n",
       "2      96.7677   96.5512   96.1780   96.4226   96.8096   96.9811   96.8336   \n",
       "3      92.1969   91.9748   91.8531   92.1156   92.3446   92.4588   92.2696   \n",
       "4      97.9493   97.5832   97.8770   97.8452   98.2188   98.1894   98.1268   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4994  102.0850  102.2880  102.4110  102.7420  102.2430  102.2220  102.2150   \n",
       "4995   97.9494   98.1799   98.3628   98.0291   98.3103   98.4854   98.0282   \n",
       "4996   96.4612   96.7232   96.9706   96.8789   96.7985   97.1090   97.2549   \n",
       "4997   97.1866   97.0617   97.2634   97.6980   97.2498   97.3879   97.5460   \n",
       "4998  101.1130  101.0970  100.8730  101.0810  101.0900  101.1650  101.3450   \n",
       "\n",
       "       305.867   306.652   307.435  ...   695.339   696.087   696.836  \\\n",
       "0      93.9844   94.2687   94.7686  ...   99.3325   99.3291   99.3268   \n",
       "1      96.0292   96.0922   96.1002  ...  100.3670  100.3130  100.2990   \n",
       "2      96.8316   97.0489   96.5584  ...  100.5560  100.5590  100.5620   \n",
       "3      92.1126   92.2204   91.8990  ...   99.0999   99.1498   99.1580   \n",
       "4      98.2943   97.7774   97.8066  ...  101.1530  101.1980  101.2170   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "4994  102.2560  102.2080  102.2340  ...  103.4040  103.4020  103.4040   \n",
       "4995   97.5581   97.6816   97.6634  ...   99.8242   99.8488   99.8604   \n",
       "4996   97.4836   97.5302   97.3204  ...   99.9035   99.9315   99.9107   \n",
       "4997   97.7210   98.4481   98.3731  ...  100.8130  100.8300  100.8580   \n",
       "4998  101.2900  101.3780  101.2470  ...  101.5080  101.5290  101.5220   \n",
       "\n",
       "       697.584   698.332   699.081   699.829   700.577  quality  color  \n",
       "0      99.3363   99.3128   99.3191   99.3499   99.3758    Faint      H  \n",
       "1     100.2630  100.2110  100.1920  100.1960  100.2210     None      J  \n",
       "2     100.5480  100.5370  100.5330  100.5110  100.4660     None      H  \n",
       "3      99.1579   99.2034   99.2142   99.2092   99.1851     None      J  \n",
       "4     101.2350  101.2070  101.2170  101.2320  101.2150     None      G  \n",
       "...        ...       ...       ...       ...       ...      ...    ...  \n",
       "4994  103.4300  103.4020  103.4220  103.4880  103.4690     None      E  \n",
       "4995   99.8668   99.8569   99.8530   99.8555   99.8538    Faint      F  \n",
       "4996   99.9335   99.9170   99.9572   99.9600   99.9568     None      G  \n",
       "4997  100.8570  100.8590  100.8910  100.9130  100.9130     None      D  \n",
       "4998  101.4920  101.5190  101.5670  101.5660  101.5690     None      D  \n",
       "\n",
       "[4993 rows x 525 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_visu.to_csv('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/Processed_data/df_train_2_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/Processed_data/df_train_2_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('/home/pankaj_v/Documents/Data_analysis_dixit/dATA/Processed_data/Feature_selected/x_se_shuff_1_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns='Unnamed: 0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns='color', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train = pd.get_dummies(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_X_train[train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['D', 'G', 'F', 'E', 'H', 'I', 'J', 'K', 'L', 'M'], dtype='object')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.value_counts().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4993, 264), (4993,))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state =42, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cv, X_test_cv, Y_train_cv, Y_test_cv = train_test_split(X_train,Y_train, test_size = 0.2, stratify = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_ = class_weight.compute_class_weight(class_weight='balanced', classes=Y.value_counts().keys(),y=Y)\n",
    "balanced = dict(zip(df_visu['color'].value_counts().keys(),balanced_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D': 0.6171817058096415,\n",
       " 'G': 0.6187112763320942,\n",
       " 'F': 0.682103825136612,\n",
       " 'E': 0.823927392739274,\n",
       " 'H': 0.8491496598639455,\n",
       " 'I': 0.9565134099616859,\n",
       " 'J': 1.0358921161825727,\n",
       " 'K': 1.4265714285714286,\n",
       " 'L': 7.8015625,\n",
       " 'M': 15.13030303030303}"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier( criterion = 'entropy',\n",
    "                            class_weight=balanced, \n",
    "                            random_state=42, \n",
    "                            warm_start=True, \n",
    "                            max_samples=None, \n",
    "                            bootstrap=True,\n",
    "                            max_depth=15,\n",
    "                            )\n",
    "grid_values = {\n",
    "    'n_estimators':[1000]\n",
    "              }\n",
    "              \n",
    "et_grid = RandomizedSearchCV(et,param_distributions= grid_values,\n",
    "    cv = 5, scoring='f1_weighted', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=ExtraTreesClassifier(bootstrap=True,\n",
       "                                                  class_weight={'D': 0.6171817058096415,\n",
       "                                                                'E': 0.823927392739274,\n",
       "                                                                'F': 0.682103825136612,\n",
       "                                                                'G': 0.6187112763320942,\n",
       "                                                                'H': 0.8491496598639455,\n",
       "                                                                'I': 0.9565134099616859,\n",
       "                                                                'J': 1.0358921161825727,\n",
       "                                                                'K': 1.4265714285714286,\n",
       "                                                                'L': 7.8015625,\n",
       "                                                                'M': 15.13030303030303},\n",
       "                                                  criterion='entropy',\n",
       "                                                  max_depth=15, random_state=42,\n",
       "                                                  warm_start=True),\n",
       "                   param_distributions={'n_estimators': [1000]},\n",
       "                   random_state=42, scoring='f1_weighted')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_grid.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True,\n",
       "                     class_weight={'D': 0.6171817058096415,\n",
       "                                   'E': 0.823927392739274,\n",
       "                                   'F': 0.682103825136612,\n",
       "                                   'G': 0.6187112763320942,\n",
       "                                   'H': 0.8491496598639455,\n",
       "                                   'I': 0.9565134099616859,\n",
       "                                   'J': 1.0358921161825727,\n",
       "                                   'K': 1.4265714285714286, 'L': 7.8015625,\n",
       "                                   'M': 15.13030303030303},\n",
       "                     criterion='entropy', max_depth=15, n_estimators=1000,\n",
       "                     random_state=42, warm_start=True)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.833772</td>\n",
       "      <td>0.352211</td>\n",
       "      <td>0.198739</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'n_estimators': 1000}</td>\n",
       "      <td>0.506344</td>\n",
       "      <td>0.547327</td>\n",
       "      <td>0.513532</td>\n",
       "      <td>0.493836</td>\n",
       "      <td>0.510107</td>\n",
       "      <td>0.514229</td>\n",
       "      <td>0.017838</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       5.833772      0.352211         0.198739        0.004792   \n",
       "\n",
       "  param_n_estimators                  params  split0_test_score  \\\n",
       "0               1000  {'n_estimators': 1000}           0.506344   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.547327           0.513532           0.493836           0.510107   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.514229        0.017838                1  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(et_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.93      0.92      0.92       109\n",
      "           E       0.85      0.89      0.87       102\n",
      "           F       0.91      0.87      0.89       128\n",
      "           G       0.83      0.87      0.85       134\n",
      "           H       0.91      0.80      0.85        99\n",
      "           I       0.81      0.79      0.80        75\n",
      "           J       0.84      0.97      0.90        79\n",
      "           K       0.95      0.92      0.93        61\n",
      "           L       0.88      1.00      0.93         7\n",
      "           M       1.00      0.80      0.89         5\n",
      "\n",
      "    accuracy                           0.88       799\n",
      "   macro avg       0.89      0.88      0.88       799\n",
      "weighted avg       0.88      0.88      0.88       799\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.97      0.98      0.97       134\n",
      "           E       0.94      0.91      0.93        91\n",
      "           F       0.89      0.88      0.88       108\n",
      "           G       0.87      0.93      0.90       146\n",
      "           H       0.89      0.85      0.87        99\n",
      "           I       0.86      0.84      0.85        83\n",
      "           J       0.91      0.91      0.91        66\n",
      "           K       0.97      0.97      0.97        59\n",
      "           L       1.00      0.91      0.95        11\n",
      "           M       0.50      0.50      0.50         2\n",
      "\n",
      "    accuracy                           0.91       799\n",
      "   macro avg       0.88      0.87      0.87       799\n",
      "weighted avg       0.91      0.91      0.91       799\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.93      0.99      0.96       142\n",
      "           E       0.93      0.86      0.90       100\n",
      "           F       0.87      0.87      0.87       117\n",
      "           G       0.86      0.87      0.86       117\n",
      "           H       0.84      0.86      0.85        80\n",
      "           I       0.89      0.86      0.88        87\n",
      "           J       0.92      0.89      0.91        91\n",
      "           K       0.90      0.95      0.92        56\n",
      "           L       1.00      0.80      0.89         5\n",
      "           M       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.90       799\n",
      "   macro avg       0.92      0.90      0.90       799\n",
      "weighted avg       0.90      0.90      0.90       799\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.94      0.98      0.96       122\n",
      "           E       0.97      0.84      0.90        99\n",
      "           F       0.91      0.93      0.92       120\n",
      "           G       0.85      0.89      0.87       108\n",
      "           H       0.82      0.88      0.85        99\n",
      "           I       0.91      0.86      0.88        93\n",
      "           J       0.85      0.90      0.87        86\n",
      "           K       0.93      0.88      0.90        58\n",
      "           L       1.00      0.80      0.89        10\n",
      "           M       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           0.90       799\n",
      "   macro avg       0.92      0.89      0.90       799\n",
      "weighted avg       0.90      0.90      0.90       799\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.97      0.94      0.96       140\n",
      "           E       0.86      0.92      0.89       106\n",
      "           F       0.90      0.90      0.90       106\n",
      "           G       0.94      0.91      0.92       133\n",
      "           H       0.87      0.92      0.90        88\n",
      "           I       0.90      0.82      0.86        90\n",
      "           J       0.87      0.89      0.88        66\n",
      "           K       0.90      1.00      0.95        56\n",
      "           L       1.00      0.67      0.80         9\n",
      "           M       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.91       798\n",
      "   macro avg       0.92      0.87      0.89       798\n",
      "weighted avg       0.91      0.91      0.91       798\n",
      "\n",
      "train_accuracy=[0.9023474178403755, 0.8938967136150234, 0.897339593114241, 0.897339593114241, 0.8945556946182729]\n",
      "f1_score=[0.8758130604606866, 0.9097805433749165, 0.8958280668152467, 0.8962837540818079, 0.9069733374591495]\n",
      " over all accuracy train_accuracy=89.70958024604307\n",
      "f1_score_mean = 89.69357524383614\n"
     ]
    }
   ],
   "source": [
    "lst_accu_stratified = []\n",
    "lst_accu_stratified_train = []\n",
    "\n",
    "\n",
    "for train_index, test_index in skf.split(X_train, Y_train):\n",
    "  x_train_fold, x_test_fold = X.iloc[train_index], X.iloc[test_index]\n",
    "  y_train_fold, y_test_fold = Y.iloc[train_index], Y.iloc[test_index]\n",
    "\n",
    "  clf_ = et\n",
    "  clf_.fit(x_train_fold, y_train_fold)\n",
    "  y_train_pred = clf_.predict(x_train_fold)\n",
    "  Y_pred = clf_.predict(x_test_fold)\n",
    "  print(classification_report(y_test_fold, Y_pred))\n",
    "\n",
    "  lst_accu_stratified.append(metrics.f1_score(y_test_fold,Y_pred,average='weighted'))\n",
    "  lst_accu_stratified_train.append(clf_.score(x_train_fold,y_train_fold))\n",
    "\n",
    "print(f\"train_accuracy={lst_accu_stratified_train}\")\n",
    "print(f\"f1_score={lst_accu_stratified}\")\n",
    "\n",
    "print(f\" over all accuracy train_accuracy={np.mean(lst_accu_stratified_train)*100}\")\n",
    "print(f\"f1_score_mean = {np.mean(lst_accu_stratified)*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds  = et.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           D       0.91      0.91      0.91       162\n",
      "           E       0.81      0.79      0.80       121\n",
      "           F       0.81      0.68      0.74       146\n",
      "           G       0.66      0.88      0.76       162\n",
      "           H       0.85      0.67      0.75       118\n",
      "           I       0.80      0.80      0.80       104\n",
      "           J       0.82      0.83      0.82        96\n",
      "           K       0.82      0.87      0.85        70\n",
      "           L       0.75      0.46      0.57        13\n",
      "           M       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           0.80       999\n",
      "   macro avg       0.82      0.75      0.77       999\n",
      "weighted avg       0.81      0.80      0.80       999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/pankaj_v/Documents/Data_analysis_dixit/Models/f1_89.05_folds.pkl']"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(\n",
    "        clf_,  \n",
    "        os.path.join('/home/pankaj_v/Documents/Data_analysis_dixit/Models', f\"f1_{round(np.mean(lst_accu_stratified)*100,2)}_folds.pkl\") \n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e49e7825c259a46fc518f8c8fed6b9fa090bf4f6d9fac061305ec26587cc5d03"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
